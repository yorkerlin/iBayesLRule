Code for ICML 2020 paper on [Handling the Positive-Definite Constraint in the Bayesian Learning Rule](https://arxiv.org/abs/2002.10060)

* To-do List:
  * Added [slides](https://github.com/yorkerlin/iBayesLRule/blob/master/slides.pdf) of the talk [done]
  * To add a [link] of the ICML talk
  * To add a Python [implementatoin](https://github.com/yorkerlin/iBayesLRule/) of the implicit reparameterization gradient for inverse Gaussian distribution (See Appendix H.1 of the paper)
  * To add a Matlab [implementation](https://github.com/yorkerlin/iBayesLRule/) for the examples using a full Gaussian approximation (See Appendix E of the paper) ![](./plots/blr2d_full.png | width=50)
  * To add a Matlab [implementation](https://github.com/yorkerlin/iBayesLRule/) for the examples using a MoG approximation (See Appendix J of the paper)
  * To add a Matlab [implementation](https://github.com/yorkerlin/iBayesLRule/) for the example using a Gamma approximation (See Appendix F of the paper)
  * To add a Python [implementation](https://github.com/yorkerlin/iBayesLRule/) for the Adam-like update using a factorized/diagonal Gaussian approximation (See Appendix E.3 of the paper)

